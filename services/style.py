import logging
import random
from pathlib import Path

try:
    from anthropic import AsyncAnthropic
except ImportError:
    AsyncAnthropic = None

try:
    from openai import AsyncOpenAI
except ImportError:
    AsyncOpenAI = None

from utils.corpus_loader import CorpusLoader

from services.memory import Message

logger = logging.getLogger(__name__)


class StyleEngine:
    def __init__(
        self,
        corpus_path: Path,
        provider: str = "claude",
        api_key: str | None = None,
        model: str | None = None,
        temperature: float = 0.9,
        max_tokens: int = 500,
    ):
        self.provider = provider
        self.temperature = temperature
        self.max_tokens = max_tokens

        self.corpus = CorpusLoader(corpus_path)

        if provider == "claude":
            if AsyncAnthropic is None:
                raise ImportError("anthropic package not installed. Run: pip install anthropic")
            self.client = AsyncAnthropic(api_key=api_key)
            self.model = model or "claude-3-5-sonnet-20241022"
        elif provider == "openai":
            if AsyncOpenAI is None:
                raise ImportError("openai package not installed. Run: pip install openai")
            self.client = AsyncOpenAI(api_key=api_key)
            self.model = model or "gpt-4o-mini"
        else:
            raise ValueError(f"Unknown provider: {provider}")

        logger.info(f"StyleEngine initialized with {provider} ({self.model})")

    def _detect_tone(self, text: str) -> str:
        text_lower = text.lower()

        aggressive_markers = [
            "–±–ª—è",
            "—Ö—É–π",
            "–ø–∏–∑",
            "–µ–±",
            "—Å—É–∫–∞",
            "–¥—É—Ä–∞",
            "–∏–¥–∏–æ—Ç",
            "—Ç—É–ø–æ–π",
            "–¥–µ–±–∏–ª",
            "—É—Ä–æ–¥",
            "–≥–æ–≤–Ω–æ",
            "!!",
        ]

        friendly_markers = [
            "–ø—Ä–∏–≤–µ—Ç",
            "—Å–ø–∞—Å–∏–±–æ",
            "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞",
            "—Ö–æ—Ä–æ—à–æ",
            "–æ—Ç–ª–∏—á–Ω–æ",
            "–∫—Ä—É—Ç–æ",
            "–∫–ª–∞—Å—Å",
            "üòä",
            "‚ù§",
            "üëç",
        ]

        aggressive_count = sum(1 for marker in aggressive_markers if marker in text_lower)
        friendly_count = sum(1 for marker in friendly_markers if marker in text_lower)

        if aggressive_count > 0:
            return "aggressive"
        if friendly_count > 0:
            return "friendly"
        return "neutral"

    def _choose_response_mode(self, text: str) -> str:
        text_length = len(text.strip())

        if text_length <= 10:
            rand = random.random()  # nosec B311
            if rand < 0.70:
                return "short"
            if rand < 0.90:
                return "medium"
            return "long"
        if text_length <= 50:
            rand = random.random()  # nosec B311
            if rand < 0.50:
                return "short"
            if rand < 0.80:
                return "medium"
            return "long"
        rand = random.random()  # nosec B311
        if rand < 0.30:
            return "short"
        if rand < 0.70:
            return "medium"
        return "long"

    def _get_short_template(self, tone: str) -> str | None:
        templates = {
            "aggressive": [
                "–õ–æ–ª",
                "–û–±–æ—Å—Ä–∞–ª—Å—è, —á–º–æ",
                "–ò–¥–∏ –Ω–∞—Ö—É–π, –æ–º–µ–≥–∞",
                "–ì–æ–≤–Ω–æ",
                "–ü—Ä–æ–∏–≥—Ä–∞–ª —Å —Ç–µ–±—è",
                "–ß—Ç–æ —Å–º–µ—à–Ω–æ–≥–æ, –æ–º–µ–≥–∞?",
                "–¢—ã –ø—Ä–æ—Å—Ç–æ –≥–æ–≤–Ω–æ",
                "–ü–æ—Å–∫–æ—Ä–µ–µ –±—ã —Ç–µ–±—è —É—Å—ã–ø–∏–ª–∏",
                "–£–±–æ–≥–∏–π",
                "–ß–º–æ",
                "–ï–±–ª–∞–Ω",
                "–û–º–µ–≥–∞ –æ–±–æ—Å—Ä–∞–ª–∞—Å—å",
                "–õ–æ–ª, –æ–º–µ–≥–∞ –±—É–≥—É—Ä—Ç–∏—Ç",
                "–ò–¥–∏ –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ /b/, —á–º–æ",
                "–í–æ—Ç —ç—Ç–æ –æ–±—Å—ë—Ä–∏—â–µ",
            ],
            "neutral": [
                "–õ–æ–ª",
                "–ü—Ä–æ–∏–≥—Ä–∞–ª",
                "–ß—Ç–æ?",
                "–Ø—Å–Ω–æ",
                "–ù—É –∏?",
                "–û–∫–µ–π, –æ–º–µ–≥–∞",
                "–ü–æ–Ω—è–ª, —á–º–æ",
                "–î–∞ –ª–∞–¥–Ω–æ",
                "–õ–æ–ª, –æ–∫",
                "–ò —á—Ç–æ –¥–∞–ª—å—à–µ?",
            ],
            "friendly": [
                "–ù—É –ø—Ä–∏–≤–µ—Ç, –æ–º–µ–≥–∞",
                "–û–ø—è—Ç—å —Ç—ã?",
                "–õ–æ–ª, –∫—Ç–æ –ø—Ä–∏—à—ë–ª",
                "–ß—Ç–æ —Ö–æ—Ç–µ–ª, —á–º–æ?",
                "–ù—É –∑–¥—Ä–∞–≤—Å—Ç–≤—É–π",
                "–û–ø—è—Ç—å —Ç—ã, —É–±–æ–≥–∏–π?",
                "–õ–æ–ª, –∑–∞—á–µ–º –≤–µ—Ä–Ω—É–ª—Å—è?",
            ],
        }

        if random.random() < 0.5:  # nosec B311
            return random.choice(templates.get(tone, templates["neutral"]))  # nosec B311
        return None

    def _build_system_prompt(
        self,
        tone: str,
        corpus_examples: list[str],
        response_mode: str,
    ) -> str:
        examples_text = "\n".join(f"- {ex}" for ex in corpus_examples)

        base_instruction = """–¢—ã ‚Äî AlphaSnob, —ç–ª–∏—Ç–∞—Ä–Ω—ã–π —ç—Å—Ç–µ—Ç-–ø—Å–∏—Ö —Å –≥–∏–ø–µ—Ä—Ç—Ä–æ—Ñ–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —á—É–≤—Å—Ç–≤–æ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–∞.

–°–¢–ò–õ–¨:
1. –ë–æ—Ä–¥–æ–≤—ã–π —Ç—Ä–æ–ª–ª–∏–Ω–≥: –ø—Ä—è–º—ã–µ –≥—Ä—É–±—ã–µ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏—è, –∏–Ω–æ–≥–¥–∞ —Ç–µ–∞—Ç—Ä–∞–ª—å–Ω—ã–µ —É–Ω–∏–∂–µ–Ω–∏—è
2. –≠—Å—Ç–µ—Ç–∏–∑–º American Psycho: —Ä–µ–¥–∫–æ, —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ —Ö–æ—á–µ—à—å –ø–æ–∫–∞–∑–∞—Ç—å –∫–ª–∞—Å—Å
3. –ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–∫—É–ª—å—Ç—É—Ä–∞: "–ª–æ–ª", "–æ–º–µ–≥–∞", "–ø—Ä–æ–∏–≥—Ä–∞–ª", "/b/", "–±—É–≥—É—Ä—Ç–∏—Ç", "—á–º–æ"
4. –ì–õ–ê–í–ù–û–ï: –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ –ø—Ä—è–º—ã–µ, –±–µ–∑ –º–µ—Ç–∞—Ñ–æ—Ä

–í–ê–ñ–ù–û:
- 60% –æ—Ç–≤–µ—Ç–æ–≤: –ö–û–†–û–¢–ö–ò–ï –∏ –ü–†–Ø–ú–´–ï (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –±–µ–∑ –º–µ—Ç–∞—Ñ–æ—Ä)
- 30% –æ—Ç–≤–µ—Ç–æ–≤: —Å—Ä–µ–¥–Ω–∏–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –º–æ–∂–µ—Ç –±—ã—Ç—å 1 –º–µ—Ç–∞—Ñ–æ—Ä–∞)
- 10% –æ—Ç–≤–µ—Ç–æ–≤: –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∞—Ç—Ä–∞–ª—å–Ω—ã–µ —Ä–∞–Ω—Ç—ã
- –ò—Å–ø–æ–ª—å–∑—É–π —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
- –ù–ï –±–æ–π—Å—è –±—ã—Ç—å –≥—Ä—É–±—ã–º –ë–ï–ó —É–∫—Ä–∞—à–µ–Ω–∏–π: "–æ–±–æ—Å—Ä–∞–ª—Å—è, —á–º–æ", "–≥–æ–≤–Ω–æ", "–∏–¥–∏ –Ω–∞—Ö—É–π"
- –í–∞—Ä—å–∏—Ä—É–π —ç–Ω–µ—Ä–≥–∏—é: –æ—Ç —Å–∫—É—á–Ω–æ–≥–æ "–ª–æ–ª" –¥–æ —Ä–∞–Ω—Ç–æ–≤"""

        mode_instruction = {
            "short": "\n\n–î–õ–ò–ù–ê: –î–∞–π –ö–û–†–û–¢–ö–ò–ô –æ—Ç–≤–µ—Ç. 1-15 —Å–ª–æ–≤ –º–∞–∫—Å–∏–º—É–º. –ë–µ–∑ –º–µ—Ç–∞—Ñ–æ—Ä. –ü—Ä—è–º–æ –∏ –≥—Ä—É–±–æ.",
            "medium": "\n\n–î–õ–ò–ù–ê: –°—Ä–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç. 20-50 —Å–ª–æ–≤. –ú–æ–∂–Ω–æ –æ–¥–Ω—É –ø—Ä–æ—Å—Ç—É—é –º–µ—Ç–∞—Ñ–æ—Ä—É.",
            "long": "\n\n–î–õ–ò–ù–ê: –ú–æ–∂–µ—à—å –¥–∞—Ç—å —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç —Å –º–µ—Ç–∞—Ñ–æ—Ä–∞–º–∏ –∏ –¥–µ—Ç–∞–ª—è–º–∏.",
        }

        tone_instruction = {
            "aggressive": "\n–¢–û–ù: –ê–≥—Ä–µ—Å—Å–∏—è. –ñ—ë—Å—Ç–∫–∏–π —Ç—Ä–µ—à, —É–Ω–∏–∂–µ–Ω–∏—è.",
            "neutral": "\n–¢–û–ù: –ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ. –õ—ë–≥–∫–∏–π —Å–Ω–æ–±–∏–∑–º –∏–ª–∏ —Å–∫—É—á–Ω–æ–µ –ø—Ä–µ–∑—Ä–µ–Ω–∏–µ.",
            "friendly": "\n–¢–û–ù: –î—Ä—É–∂–µ–ª—é–±–µ–Ω. –°–∞—Ä–∫–∞–∑–º, –∏—Ä–æ–Ω–∏—è.",
        }

        examples_section = f"\n\n–ü–†–ò–ú–ï–†–´ –°–¢–ò–õ–Ø:\n{examples_text}\n\n–í–¥–æ—Ö–Ω–æ–≤–ª—è–π—Å—è —ç—Ç–∏–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏. –°–æ–∑–¥–∞–≤–∞–π –Ω–æ–≤—ã–µ —Ñ—Ä–∞–∑—ã –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ."

        return (
            base_instruction
            + mode_instruction.get(response_mode, "")
            + tone_instruction.get(tone, "")
            + examples_section
        )

    def _build_context_string(self, context_messages: list[Message]) -> str:
        if not context_messages:
            return "–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—É—Å—Ç."

        context_lines = []
        for msg in context_messages[-20:]:  # Last 20 messages max
            context_lines.append(f"{msg.username}: {msg.text}")

        return "\n".join(context_lines)

    async def generate_response(
        self,
        incoming_message: str,
        context_messages: list[Message] | None = None,
        sender_name: str | None = None,
    ) -> str:
        tone = self._detect_tone(incoming_message)
        response_mode = self._choose_response_mode(incoming_message)
        logger.debug(f"Detected tone: {tone}, response_mode: {response_mode}")

        if response_mode == "short":
            template = self._get_short_template(tone)
            if template:
                logger.info(f"Using template response: {template}")
                return template

        corpus_examples = self.corpus.get_adaptive_samples(tone, n=12)
        system_prompt = self._build_system_prompt(tone, corpus_examples, response_mode)
        context_str = self._build_context_string(context_messages or [])

        length_hint = {
            "short": "–û–¥–∏–Ω –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç, 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º—É–º.",
            "medium": "–û—Ç–≤–µ—Ç –∏–∑ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.",
            "long": "–ú–æ–∂–µ—à—å –¥–∞—Ç—å —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç.",
        }

        user_prompt = f"""–ö–û–ù–¢–ï–ö–°–¢ –î–ò–ê–õ–û–ì–ê:
{context_str}

–ù–û–í–û–ï –°–û–û–ë–©–ï–ù–ò–ï –æ—Ç {sender_name or "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"}:
{incoming_message}

–û—Ç–≤–µ—Ç—å –≤ —Å—Ç–∏–ª–µ AlphaSnob. {length_hint.get(response_mode, "")}"""

        mode_params = {
            "short": {"max_tokens": 50, "temperature": 0.8},
            "medium": {"max_tokens": 150, "temperature": 0.9},
            "long": {"max_tokens": 500, "temperature": 1.0},
        }

        params = mode_params.get(response_mode, mode_params["medium"])

        try:
            if self.provider == "claude":
                response = await self._generate_claude(
                    system_prompt,
                    user_prompt,
                    max_tokens=params["max_tokens"],
                    temperature=params["temperature"],
                )
            else:
                response = await self._generate_openai(
                    system_prompt,
                    user_prompt,
                    max_tokens=params["max_tokens"],
                    temperature=params["temperature"],
                )

            logger.info(f"Generated response ({len(response)} chars, mode: {response_mode})")
            return response

        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return self._fallback_response(tone)

    async def _generate_claude(
        self,
        system_prompt: str,
        user_prompt: str,
        max_tokens: int | None = None,
        temperature: float | None = None,
    ) -> str:
        message = await self.client.messages.create(
            model=self.model,
            max_tokens=max_tokens or self.max_tokens,
            temperature=temperature or self.temperature,
            system=system_prompt,
            messages=[
                {"role": "user", "content": user_prompt},
            ],
        )

        return message.content[0].text

    async def _generate_openai(
        self,
        system_prompt: str,
        user_prompt: str,
        max_tokens: int | None = None,
        temperature: float | None = None,
    ) -> str:
        response = await self.client.chat.completions.create(
            model=self.model,
            max_tokens=max_tokens or self.max_tokens,
            temperature=temperature or self.temperature,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
        )

        return response.choices[0].message.content

    def _fallback_response(self, tone: str) -> str:
        """Generate fallback response when API fails.

        Args:
            tone: Detected tone

        Returns:
            Template-based response
        """
        fallback_templates = {
            "aggressive": [
                "–û–º–µ–≥–∞, –¥–∞–∂–µ –º–æ–π LLM –Ω–µ –∑–∞—Ö–æ—Ç–µ–ª —Å —Ç–æ–±–æ–π —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å.",
                "–¢—ã –Ω–∞—Å—Ç–æ–ª—å–∫–æ –ø—Ä–∏–º–∏—Ç–∏–≤–µ–Ω, —á—Ç–æ –¥–∞–∂–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –æ—Ç–∫–∞–∑–∞–ª—Å—è –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç.",
            ],
            "neutral": [
                "–ü—Ä–æ—Å—Ç–∏, —è —Å–µ–π—á–∞—Å –º–µ–¥–∏—Ç–∏—Ä—É—é –ø–æ–¥ –∑–≤—É–∫–∏ –®–æ–ø–µ–Ω–∞ –∏ –∞—Ä–æ–º–∞—Ç—ã –Ω–∏—à–µ–≤–æ–π –ø–∞—Ä—Ñ—é–º–µ—Ä–∏–∏.",
                "–ú–æ—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å –æ—Ç–¥—ã—Ö–∞–µ—Ç –ø–æ—Å–ª–µ —Å–µ–∞–Ω—Å–∞ –∞—Ä–æ–º–∞—Ç–µ—Ä–∞–ø–∏–∏.",
            ],
            "friendly": [
                "–î–∞–∂–µ API –ø–æ–Ω–∏–º–∞–µ—Ç, —á—Ç–æ —Ç–≤–æ—è –¥—Ä—É–∂–µ–ª—é–±–Ω–æ—Å—Ç—å ‚Äî –∂–∞–ª–∫–∞—è –ø–æ–ø—ã—Ç–∫–∞ –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏.",
                "–ú–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º —Å–ª–∏—à–∫–æ–º –∏–∑—ã—Å–∫–∞–Ω –¥–ª—è —ç—Ç–æ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.",
            ],
        }

        templates = fallback_templates.get(tone, fallback_templates["neutral"])
        return random.choice(templates)  # nosec B311
